services:
  # ============================================================
  #  1. PostgreSQL - Database
  # ============================================================
  postgres:
    image: postgres:16-alpine
    container_name: ragchat-postgres
    environment:
      POSTGRES_DB: ragdb
      POSTGRES_USER: raguser
      POSTGRES_PASSWORD: ragpassword
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U raguser -d ragdb"]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 10s

  # ============================================================
  #  2. Ollama - LLM Runtime
  # ============================================================
  ollama:
    image: ollama/ollama:latest
    container_name: ragchat-ollama
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 15s
    # Uncomment for GPU support:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # ============================================================
  #  3. Ollama Model Init - Auto-pull models then exit
  #     Runs once, pulls llama3.1 + llava, then stops.
  #     Backend waits for this to complete before starting.
  # ============================================================
  ollama-init:
    image: curlimages/curl:latest
    container_name: ragchat-ollama-init
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODELS=llama3.1 llava
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "=== Ollama Model Initializer ==="
        echo "Host: $$OLLAMA_HOST"
        echo "Models: $$OLLAMA_MODELS"

        for MODEL in $$OLLAMA_MODELS; do
          echo ""
          echo "--- Checking model: $$MODEL ---"

          # Check if already pulled
          if curl -sf "$$OLLAMA_HOST/api/tags" 2>/dev/null | grep -q "\"$$MODEL"; then
            echo "Model $$MODEL already exists, skipping."
          else
            echo "Pulling $$MODEL (this may take several minutes)..."
            curl -sf "$$OLLAMA_HOST/api/pull" \
              -d "{\"name\": \"$$MODEL\", \"stream\": false}" \
              --max-time 3600 && echo "✓ $$MODEL pulled!" || {
                echo "Retry pulling $$MODEL..."
                sleep 5
                curl -sf "$$OLLAMA_HOST/api/pull" \
                  -d "{\"name\": \"$$MODEL\", \"stream\": false}" \
                  --max-time 3600 && echo "✓ $$MODEL pulled on retry!" || echo "✗ Failed to pull $$MODEL"
              }
          fi
        done

        echo ""
        echo "=== Final model list ==="
        curl -sf "$$OLLAMA_HOST/api/tags" 2>/dev/null || true
        echo ""
        echo "=== Model init complete! ==="
    restart: "no"

  # ============================================================
  #  4. Data Init - Fix permissions on host-mounted volumes
  #     Ensures uid 1000 (appuser) can write to data dirs.
  # ============================================================
  data-init:
    image: alpine:latest
    container_name: ragchat-data-init
    volumes:
      - ./data/vector_store:/data/vector_store
      - ./data/documents:/data/documents
      - ./data/parser_output:/data/parser_output
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "=== Data Directory Initializer ==="
        for dir in /data/vector_store /data/documents /data/parser_output; do
          mkdir -p "$$dir"
          chown -R 1000:1000 "$$dir"
          chmod -R 755 "$$dir"
          echo "  ✓ $$dir (uid=1000)"
        done
        echo "=== Permissions set! ==="
    restart: "no"

  # ============================================================
  #  5. SearXNG - Meta Search Engine
  # ============================================================
  searxng:
    image: searxng/searxng:latest
    container_name: ragchat-searxng
    volumes:
      - ./searxng:/etc/searxng:rw
    ports:
      - "8080:8080"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8080/ > /dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 10s

  # ============================================================
  #  6. Backend - FastAPI + Multimodal RAG
  #     Waits for: postgres (healthy), ollama-init (models pulled),
  #     data-init (permissions), searxng (healthy)
  # ============================================================
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: ragchat-backend
    user: "1000:1000"
    env_file:
      - ./backend/.env
    environment:
      - DATABASE_URL=postgresql://raguser:ragpassword@postgres:5432/ragdb
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_LLM_MODEL=llama3.1
      - OLLAMA_VISION_MODEL=llava
      - VECTOR_STORE_PATH=/app/data/vector_store
      - DOCUMENTS_PATH=/app/data/documents
      - PARSER_OUTPUT_DIR=/app/data/parser_output
      - SEARXNG_URL=http://searxng:8080
    volumes:
      - ./data/vector_store:/app/data/vector_store
      - ./data/documents:/app/data/documents
      - ./data/parser_output:/app/data/parser_output
      - sentence_transformer_cache:/home/appuser/.cache/torch/sentence_transformers
    ports:
      - "8001:8000"
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_healthy
      ollama-init:
        condition: service_completed_successfully
      data-init:
        condition: service_completed_successfully
      searxng:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8000/api/health || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ============================================================
  #  7. Frontend - React
  # ============================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ragchat-frontend
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://127.0.0.1:3000/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  # ============================================================
  #  8. Nginx Reverse Proxy
  #     Only starts when both backend & frontend are healthy
  # ============================================================
  nginx:
    image: nginx:alpine
    container_name: ragchat-nginx
    ports:
      - "81:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://127.0.0.1:80/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

volumes:
  postgres_data:
  ollama_data:
  sentence_transformer_cache:
