# LocalAIChatBox - Há»‡ Thá»‘ng RAG Chat & Deep Research

<div align="center">

**Há»‡ thá»‘ng trÃ­ tuá»‡ nhÃ¢n táº¡o hoÃ n toÃ n offline cho máº¡ng ná»™i bá»™ cÃ´ng ty**

[![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/Python-3.11-green?logo=python)](https://www.python.org/)
[![React](https://img.shields.io/badge/React-18-61dafb?logo=react)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-009688?logo=fastapi)](https://fastapi.tiangolo.com/)

[TÃ­nh nÄƒng](#-tÃ­nh-nÄƒng) â€¢ [CÃ i Ä‘áº·t](#-hÆ°á»›ng-dáº«n-cÃ i-Ä‘áº·t) â€¢ [Sá»­ dá»¥ng](#-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng) â€¢ [API](#-api-endpoints) â€¢ [Cáº¥u hÃ¬nh](#-cáº¥u-hÃ¬nh-nÃ¢ng-cao)

</div>

---

## ğŸ¯ Giá»›i thiá»‡u

**LocalAIChatBox** lÃ  má»™t há»‡ thá»‘ng trÃ­ tuá»‡ nhÃ¢n táº¡o Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cháº¡y **100% offline** trÃªn máº¡ng ná»™i bá»™ cÃ´ng ty. Há»‡ thá»‘ng káº¿t há»£p:

- **RAG (Retrieval-Augmented Generation)** - Há»i Ä‘Ã¡p dá»±a trÃªn tÃ i liá»‡u cÃ´ng ty
- **Knowledge Graph** - TrÃ­ch xuáº¥t vÃ  quáº£n lÃ½ quan há»‡ thá»±c thá»ƒ tá»± Ä‘á»™ng
- **Deep Research** - NghiÃªn cá»©u sÃ¢u vá»›i tÃ¬m kiáº¿m Ä‘a bÆ°á»›c thÃ´ng minh
- **Multi-user System** - Quáº£n lÃ½ nhiá»u ngÆ°á»i dÃ¹ng vá»›i phÃ¢n quyá»n admin

### Äáº·c Ä‘iá»ƒm ná»•i báº­t

âœ… **HoÃ n toÃ n Offline** - KhÃ´ng cáº§n káº¿t ná»‘i Internet sau khi cÃ i Ä‘áº·t
âœ… **Báº£o máº­t tuyá»‡t Ä‘á»‘i** - Dá»¯ liá»‡u khÃ´ng rá»i khá»i máº¡ng ná»™i bá»™
âœ… **Dá»… dÃ ng triá»ƒn khai** - Chá»‰ 1 lá»‡nh cÃ i Ä‘áº·t tá»± Ä‘á»™ng
âœ… **MÃ£ nguá»“n má»Ÿ** - CÃ³ thá»ƒ tÃ¹y chá»‰nh theo nhu cáº§u
âœ… **Giao diá»‡n hiá»‡n Ä‘áº¡i** - Dark mode, responsive design

---

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
Máº¡ng ná»™i bá»™ cÃ´ng ty (LAN)
â”œâ”€â”€ Nginx (Port 80)             - Reverse proxy
â”œâ”€â”€ React Frontend (Port 3000)  - Giao diá»‡n web
â”œâ”€â”€ FastAPI Backend (Port 8000) - API server
â”œâ”€â”€ PostgreSQL (Port 5432)      - CÆ¡ sá»Ÿ dá»¯ liá»‡u
â”œâ”€â”€ Ollama (Port 11434)         - LLM + Embeddings
â”œâ”€â”€ SearXNG (Port 8080)         - Meta search engine
â”œâ”€â”€ FAISS Vector Store          - TÃ¬m kiáº¿m vector tÃ i liá»‡u
â””â”€â”€ Knowledge Graph (networkx)  - TrÃ­ch xuáº¥t quan há»‡ thá»±c thá»ƒ
```

**7 services** cháº¡y trong Docker containers, giao tiáº¿p qua máº¡ng Docker internal.

---

## âœ¨ TÃ­nh nÄƒng

### 1. XÃ¡c thá»±c Ä‘a ngÆ°á»i dÃ¹ng (JWT)
- ÄÄƒng kÃ½ / ÄÄƒng nháº­p
- Quáº£n lÃ½ phiÃªn lÃ m viá»‡c
- PhÃ¢n quyá»n admin / user thÆ°á»ng

### 2. Quáº£n lÃ½ tÃ i liá»‡u
- Upload: PDF, DOCX, TXT, MD
- Tá»± Ä‘á»™ng parse + chunking
- Index vÃ o FAISS vector store
- TrÃ­ch xuáº¥t thá»±c thá»ƒ vÃ o Knowledge Graph

### 3. RAG Chat (Retrieval-Augmented Generation)
- Há»i Ä‘Ã¡p dá»±a trÃªn tÃ i liá»‡u cÃ´ng ty
- TrÃ­ch dáº«n nguá»“n tá»± Ä‘á»™ng
- Toggle giá»¯a **KG-RAG** (sá»­ dá»¥ng Knowledge Graph) vÃ  **Basic RAG** (chá»‰ vector search)
- Lá»‹ch sá»­ chat riÃªng cho tá»«ng user

### 4. Knowledge Graph RAG
- **Entity Extraction**: Tá»± Ä‘á»™ng trÃ­ch xuáº¥t 7 loáº¡i thá»±c thá»ƒ (PERSON, ORGANIZATION, PROJECT, TECHNOLOGY, PRODUCT, LOCATION, CONCEPT)
- **Relationship Discovery**: PhÃ¡t hiá»‡n quan há»‡ giá»¯a cÃ¡c thá»±c thá»ƒ
- **Multi-hop Reasoning**: TÃ¬m kiáº¿m Ä‘a bÆ°á»›c thÃ´ng qua graph
- **KG Explorer**: Giao diá»‡n khÃ¡m phÃ¡ graph vá»›i search, filter, subgraph viewer

### 5. Deep Research System
- **7 chiáº¿n lÆ°á»£c nghiÃªn cá»©u**:
  - `source-based`: Theo dÃµi nguá»“n chi tiáº¿t (máº·c Ä‘á»‹nh)
  - `rapid`: Tá»‘c Ä‘á»™ cao, single-pass
  - `parallel`: TÃ¬m kiáº¿m Ä‘á»“ng thá»i Ä‘a query
  - `standard`: CÃ¢n báº±ng giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ sÃ¢u
  - `iterative`: Láº·p liÃªn tá»¥c, tÃ­ch lÅ©y kiáº¿n thá»©c
  - `focused-iteration`: Tinh chá»‰nh thÃ­ch á»©ng
  - `smart`: Tá»± Ä‘á»™ng chá»n chiáº¿n lÆ°á»£c tá»‘t nháº¥t
- **Progress tracking**: Theo dÃµi tiáº¿n Ä‘á»™ real-time
- **Report generation**: Táº¡o bÃ¡o cÃ¡o markdown chi tiáº¿t
- **Research history**: LÆ°u trá»¯ vÃ  xem láº¡i cÃ¡c nghiÃªn cá»©u cÅ©

### 6. Admin Dashboard
- Quáº£n lÃ½ ngÆ°á»i dÃ¹ng (thÃªm/xÃ³a/sá»­a)
- Thá»‘ng kÃª há»‡ thá»‘ng (sá»‘ user, tÃ i liá»‡u, entities, relationships)
- Rebuild Knowledge Graph
- Cáº¥u hÃ¬nh LDR settings (LLM, Search, Embedding)

### 7. LAN Networking
- Truy cáº­p tá»« má»i mÃ¡y tÃ­nh trong máº¡ng ná»™i bá»™
- KhÃ´ng cáº§n káº¿t ná»‘i Internet sau khi setup
- CÃ³ thá»ƒ cáº¥u hÃ¬nh SearXNG cho intranet search

---

## ğŸ“¦ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng

| ThÃ nh pháº§n | Tá»‘i thiá»ƒu | Khuyáº¿n nghá»‹ |
|------------|-----------|-------------|
| **RAM** | 16GB | 32GB |
| **Disk** | 50GB free | 100GB+ SSD |
| **CPU** | 4 cores | 8+ cores |
| **GPU** | KhÃ´ng báº¯t buá»™c | NVIDIA GPU (tÄƒng tá»‘c LLM) |

### A. CÃ i Ä‘áº·t trÃªn Ubuntu/Debian Server (Khuyáº¿n nghá»‹)

**DÃ nh cho mÃ´i trÆ°á»ng production, cháº¡y 24/7**

#### 1. CÃ i Ä‘áº·t tá»± Ä‘á»™ng (1 lá»‡nh)

TrÃªn Ubuntu 22.04+ hoáº·c Debian 12+ server má»›i:

```bash
git clone https://github.com/your-username/LocalAIChatBox.git
cd LocalAIChatBox
chmod +x setup.sh && ./setup.sh
```

Script nÃ y sáº½ tá»± Ä‘á»™ng:
1. CÃ i Ä‘áº·t Docker, Docker Compose, Git
2. Táº¡o thÆ° má»¥c `data/`, `searxng/`
3. Táº¡o SECRET_KEY ngáº«u nhiÃªn
4. Build vÃ  start 7 Docker containers
5. Download LLM model (llama3.1) vÃ o Ollama
6. Kiá»ƒm tra health cá»§a táº¥t cáº£ services

**Thá»i gian**: ~15-30 phÃºt (tÃ¹y tá»‘c Ä‘á»™ máº¡ng khi download LLM model 4.7GB)

#### 2. Sau khi cÃ i Ä‘áº·t

Truy cáº­p há»‡ thá»‘ng táº¡i: `http://<server-ip>`

ÄÄƒng nháº­p admin máº·c Ä‘á»‹nh:
- Username: `admin`
- Password: `admin123`

**âš ï¸ Quan trá»ng**: Äá»•i máº­t kháº©u admin ngay sau khi Ä‘Äƒng nháº­p láº§n Ä‘áº§u!

#### 3. TÃ¬m IP cá»§a server

```bash
hostname -I
```

VÃ­ dá»¥: `192.168.1.100`

CÃ¡c mÃ¡y trong cÃ¹ng máº¡ng LAN truy cáº­p: `http://192.168.1.100`

---

### B. CÃ i Ä‘áº·t trÃªn Windows 10/11 (Development hoáº·c Single User)

**âœ… CÃ“ THá»‚ cháº¡y trÃªn Windows 10/11!** Sá»­ dá»¥ng Docker Desktop + WSL2.

#### BÆ°á»›c 1: CÃ i Ä‘áº·t Docker Desktop

1. Táº£i Docker Desktop: https://www.docker.com/products/docker-desktop/
2. CÃ i Ä‘áº·t vÃ  khá»Ÿi Ä‘á»™ng Docker Desktop
3. KÃ­ch hoáº¡t WSL2 (Windows Subsystem for Linux 2):
   - Má»Ÿ PowerShell vá»›i quyá»n Admin:
   ```powershell
   wsl --install
   ```
   - Restart mÃ¡y tÃ­nh
   - Má»Ÿ Docker Desktop â†’ Settings â†’ General â†’ Báº­t "Use the WSL 2 based engine"

#### BÆ°á»›c 2: Clone project

Má»Ÿ **PowerShell** hoáº·c **Command Prompt**:

```powershell
git clone https://github.com/Khanhlinhdang/LocalAIChatBox.git
cd LocalAIChatBox
```

#### BÆ°á»›c 3: Táº¡o file .env

Táº¡o file `backend\.env` vá»›i ná»™i dung:

```env
SECRET_KEY=your-secret-key-here-change-this-to-random-string
DATABASE_URL=postgresql://raguser:ragpassword@postgres:5432/ragdb
OLLAMA_HOST=http://ollama:11434
OLLAMA_LLM_MODEL=llama3.1
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_PROVIDER=sentence-transformers
EMBEDDING_MODEL=all-MiniLM-L6-v2
MAX_FILE_SIZE_MB=100
ACCESS_TOKEN_EXPIRE_MINUTES=1440
SEARXNG_URL=http://searxng:8080
LDR_SEARCH_TOOL=searxng
LDR_SEARCH_ITERATIONS=3
LDR_QUESTIONS_PER_ITERATION=3
LDR_SEARCH_MAX_RESULTS=50
```

**Táº¡o SECRET_KEY ngáº«u nhiÃªn** (PowerShell):
```powershell
-join ((65..90) + (97..122) + (48..57) | Get-Random -Count 32 | % {[char]$_})
```

Copy káº¿t quáº£ vÃ o `SECRET_KEY=...`

#### BÆ°á»›c 4: Táº¡o thÆ° má»¥c SearXNG config

```powershell
mkdir searxng
```

Táº¡o file `searxng\settings.yml`:

```yaml
use_default_settings: true
general:
  instance_name: "LocalAIChatBox Search"
server:
  bind_address: "0.0.0.0:8080"
  limiter: false
  image_proxy: false
search:
  safe_search: 0
  autocomplete: ""
  default_lang: "vi"
ui:
  default_locale: "vi"
  theme_args:
    simple_style: dark
```

#### BÆ°á»›c 5: Build vÃ  start

```powershell
docker-compose up -d --build
```

**Láº§n Ä‘áº§u tiÃªn sáº½ máº¥t ~20-40 phÃºt** Ä‘á»ƒ:
- Build images (~10 phÃºt)
- Download LLM model llama3.1 (~4.7GB) vÃ o container ollama

#### BÆ°á»›c 6: Download LLM model

```powershell
docker exec -it ragchat-ollama ollama pull llama3.1
```

Äá»£i download hoÃ n thÃ nh (4.7GB).

#### BÆ°á»›c 7: Kiá»ƒm tra services

```powershell
docker-compose ps
```

Táº¥t cáº£ services pháº£i cÃ³ status `Up` hoáº·c `healthy`.

#### BÆ°á»›c 8: Truy cáº­p

Má»Ÿ trÃ¬nh duyá»‡t:
- **TrÃªn mÃ¡y Windows hiá»‡n táº¡i**: http://localhost
- **Tá»« mÃ¡y khÃ¡c trong máº¡ng LAN**: http://<IP-cá»§a-mÃ¡y-Windows>

**TÃ¬m IP cá»§a mÃ¡y Windows**:
```powershell
ipconfig
```

TÃ¬m dÃ²ng `IPv4 Address` cá»§a adapter máº¡ng Ä‘ang dÃ¹ng (VD: `192.168.1.50`)

---

### C. CÃ i Ä‘áº·t thá»§ cÃ´ng (Manual setup)

Náº¿u báº¡n muá»‘n kiá»ƒm soÃ¡t tá»«ng bÆ°á»›c:

#### 1. CÃ i Ä‘áº·t dependencies

**Ubuntu/Debian**:
```bash
sudo apt update
sudo apt install -y docker.io docker-compose git
sudo systemctl enable docker
sudo systemctl start docker
sudo usermod -aG docker $USER
```

**Windows**: CÃ i Docker Desktop nhÆ° hÆ°á»›ng dáº«n á»Ÿ pháº§n B.

#### 2. Clone repo

```bash
git clone https://github.com/your-username/LocalAIChatBox.git
cd LocalAIChatBox
```

#### 3. Táº¡o file config

- Táº¡o `backend/.env` (xem template á»Ÿ pháº§n B bÆ°á»›c 3)
- Táº¡o `searxng/settings.yml` (xem template á»Ÿ pháº§n B bÆ°á»›c 4)

#### 4. Build vÃ  start

```bash
docker-compose up -d --build
```

#### 5. Download LLM model

```bash
docker exec -it ragchat-ollama ollama pull llama3.1
```

#### 6. Kiá»ƒm tra

```bash
docker-compose ps
curl http://localhost/api/health
```

---

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. ÄÄƒng nháº­p

Truy cáº­p `http://<server-ip>` â†’ ÄÄƒng nháº­p vá»›i `admin` / `admin123`

### 2. Upload tÃ i liá»‡u

**Documents** page â†’ **Upload Documents** â†’ Chá»n file (PDF, DOCX, TXT, MD)

Há»‡ thá»‘ng tá»± Ä‘á»™ng:
- Parse vÃ  chunk text
- Táº¡o vector embeddings
- Index vÃ o FAISS
- TrÃ­ch xuáº¥t entities vÃ  relationships vÃ o Knowledge Graph

### 3. Chat vá»›i tÃ i liá»‡u (RAG)

**Chat** page â†’ Nháº­p cÃ¢u há»i

Toggle **KG-RAG** / **Basic RAG**:
- **KG-RAG**: Sá»­ dá»¥ng cáº£ vector search + knowledge graph (khuyáº¿n nghá»‹)
- **Basic RAG**: Chá»‰ vector search (nhanh hÆ¡n, Ã­t context hÆ¡n)

Káº¿t quáº£ hiá»ƒn thá»‹:
- CÃ¢u tráº£ lá»i
- Nguá»“n trÃ­ch dáº«n (document + page)
- Entities liÃªn quan (náº¿u dÃ¹ng KG-RAG)

### 4. KhÃ¡m phÃ¡ Knowledge Graph

**Graph** page â†’ Xem thá»‘ng kÃª, search entities, click vÃ o entity Ä‘á»ƒ xem subgraph

**Admin only**: Rebuild Graph (xá»­ lÃ½ láº¡i táº¥t cáº£ documents)

### 5. Deep Research

**Research** page â†’ Nháº­p research query â†’ Chá»n strategy â†’ **Start Research**

VÃ­ dá»¥ query:
- "TÃ³m táº¯t cÃ¡c xu hÆ°á»›ng AI trong 2024"
- "So sÃ¡nh React vs Vue.js"
- "PhÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm cá»§a Kubernetes"

Theo dÃµi progress real-time â†’ Xem findings â†’ **Generate Report** Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o chi tiáº¿t

### 6. Cáº¥u hÃ¬nh há»‡ thá»‘ng (Admin)

**Settings** page â†’ Chá»‰nh sá»­a:
- **LLM**: Provider, model, temperature, Ollama URL
- **Search**: Tool (searxng/duckduckgo/wikipedia), iterations, questions per iteration, max results
- **Embedding**: Provider (sentence-transformers/ollama), model
- **Report**: Searches per section

â†’ **Save Settings**

---

## ğŸ“¡ API Endpoints

### Authentication

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| POST | `/api/auth/register` | - | ÄÄƒng kÃ½ user má»›i |
| POST | `/api/auth/login` | - | ÄÄƒng nháº­p (tráº£ vá» JWT token) |
| GET | `/api/auth/me` | User | Láº¥y thÃ´ng tin user hiá»‡n táº¡i |
| PUT | `/api/auth/password` | User | Äá»•i máº­t kháº©u |

### Chat

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| POST | `/api/chat/query` | User | Há»i Ä‘Ã¡p RAG (body: `{query, use_knowledge_graph}`) |
| GET | `/api/chat/history` | User | Láº¥y lá»‹ch sá»­ chat |
| DELETE | `/api/chat/history` | User | XÃ³a lá»‹ch sá»­ chat |

### Documents

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| POST | `/api/documents/upload` | User | Upload tÃ i liá»‡u (form-data: files[]) |
| GET | `/api/documents/list` | User | Danh sÃ¡ch tÃ i liá»‡u |
| DELETE | `/api/documents/{id}` | User | XÃ³a tÃ i liá»‡u |

### Knowledge Graph

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| GET | `/api/knowledge-graph/stats` | User | Thá»‘ng kÃª KG (entities, relationships, types) |
| GET | `/api/knowledge-graph/entities` | User | Danh sÃ¡ch táº¥t cáº£ entities |
| GET | `/api/knowledge-graph/search?q={name}` | User | Search entities theo tÃªn |
| GET | `/api/knowledge-graph/entity/{name}?hops=2` | User | Láº¥y subgraph cá»§a entity (hops = Ä‘á»™ sÃ¢u) |
| POST | `/api/knowledge-graph/rebuild` | Admin | Rebuild KG tá»« táº¥t cáº£ documents |

### Deep Research

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| POST | `/api/research/start` | User | Báº¯t Ä‘áº§u deep research (body: `{query, strategy}`) |
| GET | `/api/research/{task_id}/progress` | User | Polling progress (status, %, message) |
| GET | `/api/research/{task_id}/result` | User | Láº¥y káº¿t quáº£ (findings, sources) |
| POST | `/api/research/{task_id}/report` | User | Táº¡o bÃ¡o cÃ¡o markdown chi tiáº¿t |
| GET | `/api/research/history?limit=20` | User | Lá»‹ch sá»­ research tasks |
| DELETE | `/api/research/{task_id}` | User | XÃ³a research task |
| GET | `/api/research/strategies` | User | Danh sÃ¡ch 7 strategies cÃ³ sáºµn |

### Settings (Admin only)

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| GET | `/api/settings/ldr` | Admin | Láº¥y táº¥t cáº£ LDR settings |
| PUT | `/api/settings/ldr` | Admin | Cáº­p nháº­t LDR settings (body: `{settings: {...}}`) |

### Admin

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| GET | `/api/admin/stats` | Admin | Thá»‘ng kÃª há»‡ thá»‘ng |
| GET | `/api/admin/users` | Admin | Danh sÃ¡ch users |
| PUT | `/api/admin/users/{id}` | Admin | Cáº­p nháº­t user (is_admin, is_active) |
| DELETE | `/api/admin/users/{id}` | Admin | XÃ³a user |

### System

| Method | Endpoint | Auth | MÃ´ táº£ |
|--------|----------|------|-------|
| GET | `/api/health` | - | Health check |

**API Docs (Swagger)**: `http://<server-ip>/docs`

---

## âš™ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### 1. Biáº¿n mÃ´i trÆ°á»ng (.env)

File: `backend/.env`

| Biáº¿n | MÃ´ táº£ | Máº·c Ä‘á»‹nh |
|------|-------|----------|
| `SECRET_KEY` | JWT secret key | Auto-generated |
| `DATABASE_URL` | PostgreSQL connection string | `postgresql://raguser:ragpassword@postgres:5432/ragdb` |
| `OLLAMA_HOST` | Ollama API URL | `http://ollama:11434` |
| `OLLAMA_LLM_MODEL` | LLM model name | `llama3.1` |
| `OLLAMA_EMBEDDING_MODEL` | Embedding model (náº¿u dÃ¹ng Ollama) | `nomic-embed-text` |
| `EMBEDDING_PROVIDER` | `sentence-transformers` hoáº·c `ollama` | `sentence-transformers` |
| `EMBEDDING_MODEL` | Model cho sentence-transformers | `all-MiniLM-L6-v2` |
| `MAX_FILE_SIZE_MB` | Giá»›i háº¡n upload file | `100` |
| `ACCESS_TOKEN_EXPIRE_MINUTES` | Token expiry | `1440` (24h) |
| `SEARXNG_URL` | SearXNG API URL | `http://searxng:8080` |
| `LDR_SEARCH_TOOL` | Search tool cho LDR | `searxng` |
| `LDR_SEARCH_ITERATIONS` | Sá»‘ vÃ²ng láº·p search | `3` |
| `LDR_QUESTIONS_PER_ITERATION` | Sá»‘ cÃ¢u há»i má»—i vÃ²ng láº·p | `3` |
| `LDR_SEARCH_MAX_RESULTS` | Sá»‘ káº¿t quáº£ tá»‘i Ä‘a má»—i search | `50` |

### 2. KÃ­ch hoáº¡t GPU (NVIDIA)

Náº¿u server cÃ³ GPU NVIDIA, bá» comment trong `docker-compose.yml`:

```yaml
ollama:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
```

**YÃªu cáº§u**: CÃ i Ä‘áº·t NVIDIA Container Toolkit trÃªn host

```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
sudo apt update
sudo apt install -y nvidia-container-toolkit
sudo systemctl restart docker
```

Restart containers:
```bash
docker-compose down
docker-compose up -d
```

### 3. Thay Ä‘á»•i LLM model

Download model khÃ¡c tá»« Ollama:

```bash
# Xem danh sÃ¡ch model: https://ollama.com/library
docker exec -it ragchat-ollama ollama pull mistral
docker exec -it ragchat-ollama ollama pull phi3
```

Cáº­p nháº­t `backend/.env`:
```env
OLLAMA_LLM_MODEL=mistral
```

Restart backend:
```bash
docker-compose restart backend
```

### 4. Cáº¥u hÃ¬nh SearXNG cho intranet

Edit `searxng/settings.yml` Ä‘á»ƒ thÃªm engines tÃ¹y chá»‰nh:

```yaml
engines:
  - name: company_wiki
    engine: xpath
    search_url: http://wiki.company.local/search?q={query}
    url_xpath: //a[@class="result-link"]/@href
    title_xpath: //a[@class="result-link"]/text()
    content_xpath: //p[@class="snippet"]/text()
    shortcut: cw
    disabled: false
```

Restart SearXNG:
```bash
docker-compose restart searxng
```

### 5. Backup vÃ  Restore

#### Backup

```bash
# Backup database
docker exec ragchat-postgres pg_dump -U raguser ragdb > backup_$(date +%Y%m%d).sql

# Backup vector store + documents
tar -czf data_backup_$(date +%Y%m%d).tar.gz data/
```

#### Restore

```bash
# Restore database
cat backup_YYYYMMDD.sql | docker exec -i ragchat-postgres psql -U raguser -d ragdb

# Restore data
tar -xzf data_backup_YYYYMMDD.tar.gz
```

---

## ğŸ› ï¸ Lá»‡nh há»¯u Ã­ch

### Docker Compose

```bash
# Xem logs táº¥t cáº£ services
docker-compose logs -f

# Xem logs cá»§a 1 service
docker-compose logs -f backend

# Restart services
docker-compose restart

# Stop táº¥t cáº£
docker-compose down

# Stop vÃ  xÃ³a volumes (XÃ“A Dá»® LIá»†U!)
docker-compose down -v

# Rebuild image
docker-compose build --no-cache backend
docker-compose up -d backend

# Xem status
docker-compose ps

# Xem tÃ i nguyÃªn sá»­ dá»¥ng
docker stats
```

### Ollama

```bash
# List models Ä‘Ã£ download
docker exec ragchat-ollama ollama list

# Pull model má»›i
docker exec ragchat-ollama ollama pull llama3.1

# XÃ³a model
docker exec ragchat-ollama ollama rm llama3.1

# Test model
docker exec -it ragchat-ollama ollama run llama3.1 "Hello"
```

### Database

```bash
# Káº¿t ná»‘i PostgreSQL CLI
docker exec -it ragchat-postgres psql -U raguser -d ragdb

# SQL commands:
\dt                    # List tables
\d research_tasks      # Describe table
SELECT COUNT(*) FROM users;
```

### SearXNG

```bash
# Test SearXNG
curl "http://localhost:8080/search?q=test&format=json" | jq .

# Restart SearXNG
docker-compose restart searxng
```

---

## ğŸ” Troubleshooting

### 1. Backend khÃ´ng start

**Triá»‡u chá»©ng**: `docker-compose ps` hiá»‡n backend status `Restarting` hoáº·c `Exited`

**Kiá»ƒm tra logs**:
```bash
docker-compose logs backend
```

**NguyÃªn nhÃ¢n thÆ°á»ng gáº·p**:
- PostgreSQL chÆ°a ready â†’ Äá»£i 30s vÃ  kiá»ƒm tra láº¡i
- `.env` file thiáº¿u hoáº·c sai format â†’ Kiá»ƒm tra láº¡i file
- Port 8000 bá»‹ chiáº¿m â†’ Äá»•i port trong `docker-compose.yml`

### 2. Ollama khÃ´ng download model

**Triá»‡u chá»©ng**: `docker exec -it ragchat-ollama ollama pull llama3.1` bá»‹ lá»—i

**Kiá»ƒm tra**:
```bash
docker logs ragchat-ollama
```

**NguyÃªn nhÃ¢n**:
- KhÃ´ng cÃ³ káº¿t ná»‘i Internet â†’ Cáº§n Internet Ä‘á»ƒ download model láº§n Ä‘áº§u
- Disk full â†’ Kiá»ƒm tra `df -h`
- OOM (out of memory) â†’ TÄƒng RAM hoáº·c swap

**Giáº£i phÃ¡p**: Download model offline:
1. Táº£i model tá»« https://ollama.com/library/llama3.1 trÃªn mÃ¡y khÃ¡c
2. Copy vÃ o server: `scp llama3.1.gguf user@server:/tmp/`
3. Import: `docker exec ragchat-ollama ollama create llama3.1 -f /tmp/llama3.1.gguf`

### 3. Frontend khÃ´ng káº¿t ná»‘i backend

**Triá»‡u chá»©ng**: TrÃªn trÃ¬nh duyá»‡t, console hiá»ƒn thá»‹ "Network Error"

**Kiá»ƒm tra**:
```bash
curl http://localhost/api/health
```

**NguyÃªn nhÃ¢n**:
- Nginx config sai â†’ Xem logs: `docker-compose logs nginx`
- Backend chÆ°a ready â†’ Äá»£i backend start xong
- Firewall cháº·n port 80 â†’ Má»Ÿ port: `sudo ufw allow 80`

### 4. Deep Research khÃ´ng hoáº¡t Ä‘á»™ng

**Triá»‡u chá»©ng**: Research task bá»‹ stuck á»Ÿ "pending" hoáº·c "running" khÃ´ng tiáº¿n triá»ƒn

**Kiá»ƒm tra**:
```bash
docker-compose logs backend | grep "research"
```

**NguyÃªn nhÃ¢n**:
- SearXNG khÃ´ng hoáº¡t Ä‘á»™ng â†’ Test: `curl http://localhost:8080`
- LLM model chÆ°a download â†’ Kiá»ƒm tra: `docker exec ragchat-ollama ollama list`
- Backend OOM â†’ Kiá»ƒm tra: `docker stats`

**Giáº£i phÃ¡p**:
```bash
# Restart toÃ n bá»™ services
docker-compose restart

# Rebuild backend náº¿u code thay Ä‘á»•i
docker-compose build backend && docker-compose up -d backend
```

### 5. Windows 10: Docker Desktop khÃ´ng start

**Triá»‡u chá»©ng**: Docker Desktop hiá»ƒn thá»‹ "Starting..." mÃ£i khÃ´ng xong

**Giáº£i phÃ¡p**:
1. Kiá»ƒm tra WSL2: `wsl --status`
2. Náº¿u chÆ°a cÃ i: `wsl --install`
3. Restart mÃ¡y
4. Báº­t Virtualization trong BIOS (Intel VT-x / AMD-V)
5. Reinstall Docker Desktop

### 6. KhÃ´ng truy cáº­p Ä‘Æ°á»£c tá»« mÃ¡y khÃ¡c trong LAN

**Triá»‡u chá»©ng**: TrÃªn mÃ¡y Windows cÃ³ thá»ƒ truy cáº­p `http://localhost`, nhÆ°ng tá»« mÃ¡y khÃ¡c khÃ´ng Ä‘Æ°á»£c

**Windows Firewall**:
```powershell
# Má»Ÿ PowerShell vá»›i quyá»n Admin
New-NetFirewallRule -DisplayName "LocalAIChatBox" -Direction Inbound -Protocol TCP -LocalPort 80 -Action Allow
```

**Kiá»ƒm tra IP**:
```powershell
ipconfig
# TÃ¬m IPv4 Address cá»§a adapter Ä‘ang dÃ¹ng
```

**Test tá»« mÃ¡y khÃ¡c**:
```bash
ping <IP-cá»§a-mÃ¡y-Windows>
curl http://<IP-cá»§a-mÃ¡y-Windows>/api/health
```

---

## ğŸ“Š Monitoring

### Health check

```bash
# Backend health
curl http://localhost/api/health
# Káº¿t quáº£: {"status":"ok","services":{"database":"ok","ollama":"ok"}}

# Check all containers
docker-compose ps
```

### Resource usage

```bash
docker stats --no-stream
```

Theo dÃµi:
- **CPU%**: Ollama thÆ°á»ng 50-200% khi Ä‘ang inference
- **MEM USAGE**: Backend ~2-4GB, Ollama ~4-8GB (tÃ¹y model)
- **NET I/O**: Kiá»ƒm tra traffic giá»¯a containers

### Logs

```bash
# Real-time logs
docker-compose logs -f --tail=100

# Filter by service
docker-compose logs -f backend

# Filter by keyword
docker-compose logs | grep ERROR
```

---

## ğŸ” Báº£o máº­t

### 1. Äá»•i máº­t kháº©u máº·c Ä‘á»‹nh

**Admin password**: ÄÄƒng nháº­p â†’ User menu â†’ Change Password

**PostgreSQL password**: Edit `docker-compose.yml` vÃ  `backend/.env`:
```yaml
# docker-compose.yml
POSTGRES_PASSWORD: new-secure-password

# backend/.env
DATABASE_URL=postgresql://raguser:new-secure-password@postgres:5432/ragdb
```

Restart:
```bash
docker-compose down
docker-compose up -d
```

### 2. Táº¡o SECRET_KEY máº¡nh

```bash
# Linux/Mac
openssl rand -hex 32

# Windows PowerShell
-join ((65..90) + (97..122) + (48..57) | Get-Random -Count 32 | % {[char]$_})
```

Cáº­p nháº­t vÃ o `backend/.env`:
```env
SECRET_KEY=your-new-32-char-random-string-here
```

### 3. Giá»›i háº¡n truy cáº­p máº¡ng

**Nginx**: Chá»‰ cho phÃ©p truy cáº­p tá»« LAN

Edit `nginx/nginx.conf`:
```nginx
server {
    listen 80;

    # Chá»‰ cho phÃ©p LAN
    allow 192.168.0.0/16;
    allow 10.0.0.0/8;
    deny all;

    # ... rest of config
}
```

Restart: `docker-compose restart nginx`

### 4. HTTPS (SSL/TLS)

Äá»ƒ enable HTTPS, thÃªm vÃ o `nginx/nginx.conf`:

```nginx
server {
    listen 443 ssl;
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;

    # ... rest of config
}
```

Mount SSL certs:
```yaml
# docker-compose.yml
nginx:
  volumes:
    - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    - ./nginx/ssl:/etc/nginx/ssl:ro
```

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```
LocalAIChatBox/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPI app, lifespan events
â”‚   â”‚   â”œâ”€â”€ models.py              # SQLAlchemy models (User, Document, ChatHistory, ResearchTask, ResearchSetting)
â”‚   â”‚   â”œâ”€â”€ database.py            # Database connection
â”‚   â”‚   â”œâ”€â”€ auth.py                # JWT authentication, password hashing
â”‚   â”‚   â”œâ”€â”€ rag_engine.py          # FAISS + sentence-transformers RAG
â”‚   â”‚   â”œâ”€â”€ document_processor.py  # PDF/DOCX/TXT/MD parsing
â”‚   â”‚   â”œâ”€â”€ knowledge_graph.py     # NetworkX KG, entity extraction
â”‚   â”‚   â”œâ”€â”€ deep_research.py       # DeepResearchService (LDR wrapper)
â”‚   â”‚   â”œâ”€â”€ ldr_settings.py        # LDR settings adapter
â”‚   â”‚   â””â”€â”€ research_routes.py     # Deep Research API endpoints
â”‚   â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile                 # Multi-stage build
â”‚   â””â”€â”€ .env                       # Environment variables
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ Navbar.jsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginPage.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ RegisterPage.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPage.jsx          # RAG chat UI
â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentsPage.jsx      # Document management
â”‚   â”‚   â”‚   â”œâ”€â”€ AdminPage.jsx          # User management
â”‚   â”‚   â”‚   â”œâ”€â”€ KnowledgeGraphPage.jsx # KG explorer
â”‚   â”‚   â”‚   â”œâ”€â”€ DeepResearchPage.jsx   # Deep Research UI
â”‚   â”‚   â”‚   â””â”€â”€ SettingsPage.jsx       # LDR settings (admin)
â”‚   â”‚   â”œâ”€â”€ api.js                     # Axios API client
â”‚   â”‚   â”œâ”€â”€ App.jsx                    # Main app, routes
â”‚   â”‚   â”œâ”€â”€ App.css                    # Global styles
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ Dockerfile                     # Nginx + React build
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ nginx/
â”‚   â””â”€â”€ nginx.conf                     # Reverse proxy config
â”œâ”€â”€ searxng/
â”‚   â””â”€â”€ settings.yml                   # SearXNG config
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/                     # Uploaded files
â”‚   â”œâ”€â”€ vector_store/                  # FAISS index files
â”‚   â””â”€â”€ database/                      # PostgreSQL data (managed by Docker volume)
â”œâ”€â”€ local-deep-research/               # LDR package (git submodule hoáº·c copy)
â”‚   â”œâ”€â”€ local_deep_research/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search_system.py           # AdvancedSearchSystem
â”‚   â”‚   â”œâ”€â”€ report_generator.py        # IntegratedReportGenerator
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_config.py          # get_llm()
â”‚   â”‚   â”‚   â””â”€â”€ search_config.py       # get_search()
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ setup.py
â”œâ”€â”€ docker-compose.yml                 # 7 services orchestration
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ setup.sh                           # Automated setup script (Ubuntu/Debian)
â””â”€â”€ README.md                          # This file
```

---

## ğŸ¤ ÄÃ³ng gÃ³p

Dá»± Ã¡n mÃ£ nguá»“n má»Ÿ, chÃ o Ä‘Ã³n má»i Ä‘Ã³ng gÃ³p:

1. Fork repo
2. Táº¡o branch: `git checkout -b feature/your-feature`
3. Commit: `git commit -m "Add your feature"`
4. Push: `git push origin feature/your-feature`
5. Táº¡o Pull Request

---

## ğŸ“„ License

MIT License - Xem file `LICENSE` Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

---

## ğŸ“ Há»— trá»£

- **Issues**: https://github.com/your-username/LocalAIChatBox/issues
- **Wiki**: https://github.com/your-username/LocalAIChatBox/wiki
- **Discussions**: https://github.com/your-username/LocalAIChatBox/discussions

---

## ğŸ“ TÃ i liá»‡u tham kháº£o

- **Ollama**: https://ollama.com/
- **LangChain**: https://python.langchain.com/
- **FAISS**: https://github.com/facebookresearch/faiss
- **SearXNG**: https://docs.searxng.org/
- **Sentence Transformers**: https://www.sbert.net/
- **FastAPI**: https://fastapi.tiangolo.com/
- **React**: https://react.dev/

---

<div align="center">

**LocalAIChatBox** - Há»‡ thá»‘ng AI hoÃ n toÃ n offline cho doanh nghiá»‡p

Made with â¤ï¸ by [Your Name/Team]

</div>


ğŸš€ VI. Lá»˜ TRÃŒNH Æ¯U TIÃŠN (Roadmap)
Phase 1: Production Hardening (1-2 thÃ¡ng)
âœ… Add logging (structlog + ELK/Loki)
âœ… Add monitoring (Prometheus + Grafana)
âœ… Implement backup/restore scripts
âœ… Add unit + integration tests (target: 70% coverage)
âœ… Setup CI/CD pipeline (GitHub Actions)
âœ… Add audit logging system
Phase 2: Performance & Scale (1-2 thÃ¡ng)
âœ… Migrate ChromaDB â†’ Qdrant/Milvus
âœ… Implement Redis caching
âœ… Enable GPU support + quantized models
âœ… Add response streaming (SSE)
âœ… Migrate deep research â†’ Celery + Redis
âœ… Load testing & optimization
Phase 3: Feature Enhancement (2-3 thÃ¡ng)
âœ… Document versioning & folders
âœ… Chat history with context (multi-turn)
âœ… Interactive KG visualization (D3.js/Cytoscape)
âœ… Advanced filters & faceted search
âœ… Usage analytics dashboard
âœ… Export features (chat, reports, graphs)
Phase 4: Enterprise Features (2-3 thÃ¡ng)
âœ… LDAP/AD integration (SSO)
âœ… RBAC (Role-Based Access Control)
âœ… Per-document permissions
âœ… Encryption at rest
âœ… Compliance reports (GDPR, etc.)
âœ… Multi-tenancy support